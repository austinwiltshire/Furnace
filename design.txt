FEATURES:

* Critical Path:
** Imminent (Version 2):
*** 1. add helper function for current baseline - 20% stocks or whever i decided on. that way i can easily compare new strategies cagr/simple sharpe
*** 2. Add real estate index ( go for history) (compare to baseline)
*** 3. Add currency index and/or money market (compare to new baseline)
*** 4. Add commodities index (compare to new baseline)
*** 5. Create last period (momentum) forecast of CAGR
*** 6. Create last period forecast of volatility
*** 7. Create portfolio that weights based on proportional simplified sharpes (no correlation) (compare spy & bonds to baseline, then add new assets to reconfirm)
*** 8. Create auto regression forecast of CAGR (compare to simple momentum)
*** 9. Tag as version 2!

** Anticipated:
*** add max drawdown to performance
*** add comissions handling
*** expected return between two dates, including dates that we havent' calculated yet for forecasting (on overall performance, or strategy)
*** plot portfolio - like plot index but takes a value and accounts for comissions in absolute terms (overall performance)
*** Add precious metals index
*** Manufacture volatility strategy - should I trade vixx or make my own iron condors?
*** Add real portfolio optimization with correlations
*** calculate true sharpe by adjusting returns and volatility by returns and volatility of the risk free asset
*** ./furnace/strategy.py:64: #TODO: should forecast be similar to asset universe, except it also provides expectations on those assets?

* Bells and Whistles
** add in metadata to allow for readable debugging and plots? i..e, be nice if the plot auto-named it as "Total return of Buy-And-Hold Single Asset with historical forecast on SPY"
   could take in metadata from portfolio strategy (buy and hold single asset), forecast (historical forecast) and asset universe (spy). probably also rebalance rule

* Tabled
** panels for different stocks?
** accrue dividends if you create cap gains models separate from dividends.

PRODUCTIVITY:

* ipython has integration with vim
* install emacs, evil and org
* nerd tree should hide pyc
* nerd tree bookmarks
* get vim to point swp and un~ files somewhere else
* git flow

BUGS:

REFACTORS:

* General
** add doctests to public methods
+ maintainability
- large scope

** separate out stuff that isn't tested into modules that can be hit with system tests to generate coverage that way. maybe entirely different project?
+ test coverage
+ quality
- medium scope

** check __iter__ functions to see if we can't refactor their use to inside the object that provides them - then remove __iters__
+ encapsulation
- large scope

** adding a _repr_ function helps ipython
+ debugability
- very large scope

ARCHITECTURE:

* all returns are calculated as 0.01 for 1% return. A stock that is valued at $100 that has a 1% return will be valued at $101
NOTES:

* to drop into ipython:

import IPython
IPython.embed()

only run one test at a time, won't work on multicore or multi test mode

* to calculate technical debt:

do a count of todos
divide by adjusted physical lines of code

* to get adjusted physical lines:

run metrics
take out line count for 'class'
take out line count for 'def'

* assertion density:

to count assertions
grep assert `find . -regex ".*\.py" | grep -v test` | wc -l 
that takes out tests. divide that by adjusted line count

* to capture todos

grep TODO -n `find . -regex ".*\.py"` 

-n gets the line number

* to calculate metrics:

find . -regex ".*\.py" | xargs metrics

* to run tests continuously:
py.test -n 4 --looponfail

* for coverage reports, from root of project
py.test -n 4 --cov-config _coverage.rc --cov furnace --cov-report html

* to run a single test
py.test -q -s furnace/tests/test_file.py::ClassName

* code smell:

grep pylint `find . -regex ".*\.py"` | wc -l

divide by 2 since each pylint exception is turned on then off.
divide by adjusted lines

* in ipython:
** ctrl-a moves to begin of line
** ctrl-e moves to end of line

* libs learned:
** pandas

* libs to read:
** scikit-learn
** quantlib
** statsmodels
** scipy
** numpy

* interesting metrics to track:

** number of #pylint: lines. 
lower is better, means i'm closer to pylint's suggested style and make fewer exceptions ('code smell'? so long as it's pylint clean) 2.3% at last check, goal is 2%

** number of todo's, number of todo's / logical line count - technical debt
technical debt (todos / adjusted line count) - last check was 4.97%, go for 4%

** test coverage %, test path coverage %, test logical line count / logical line count, #tests / #functions (public functions)
** assertion density - last check was 4.47%, go for 5%

** comment and docstring length / adjusted logical lines
** something for code modularity? average file size or maybe just look for certain file sizes? not just line count but also method or class count?

* principles:
** *REMEMBER*: eliminate waste before improving quality. then you have less work to do!

** cycle:
*** feature push
*** code audit
*** plan triage
*** metrics check and adjust. keep coverage up, etc

